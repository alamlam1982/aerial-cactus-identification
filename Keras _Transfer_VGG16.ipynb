{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.applications import VGG16\nfrom keras.optimizers import Adam","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"5ce02603d1cb61f7cc1a893b2c0a46bf069b1c47"},"cell_type":"code","source":"train_dir = \"../input/train/train/\"\ntest_dir = \"../input/test/test/\"\ntrain_df = pd.read_csv('../input/train.csv')\ntrain_df.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                                     id  has_cactus\n0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n2  000d1e9a533f62e55c289303b072733d.jpg           1\n3  0011485b40695e9138e92d0b3fb55128.jpg           1\n4  0014d7a11e90b62848904c1418fc8cf2.jpg           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"18696a140232bc437a097852473239c7519f6871"},"cell_type":"code","source":"im = cv2.imread(\"../input/train/train/01e30c0ba6e91343a12d2126fcafc0dd.jpg\")\nplt.imshow(im)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7fe78b50c7b8>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"d4290802c9484d9cf8afe14a975423531c64e18f"},"cell_type":"code","source":"vgg16_net = VGG16(weights='imagenet', \n                  include_top=False, \n                  input_shape=(32, 32, 3))","execution_count":7,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"070ea255ed183fd2e9636b978db571b86b2bdd7d","scrolled":true},"cell_type":"code","source":"vgg16_net.trainable = False\nvgg16_net.summary()","execution_count":8,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 32, 32, 3)         0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 0\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"1c021705cdba972c0bbfbbef00d9b1e145617832"},"cell_type":"code","source":"model = Sequential()\nmodel.add(vgg16_net)\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","execution_count":9,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"088a5fe47727a896187abd98dda397f2ef8f0759"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=Adam(lr=1e-5), \n              metrics=['accuracy'])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f19d0ac61d1406e1e2fe1ab898b19fccdd103ef7"},"cell_type":"code","source":"X_tr = []\nY_tr = []\nimges = train_df['id'].values\nfor img_id in tqdm_notebook(imges):\n    X_tr.append(cv2.imread(train_dir + img_id))    \n    Y_tr.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \nX_tr = np.asarray(X_tr)\nX_tr = X_tr.astype('float32')\nX_tr /= 255\nY_tr = np.asarray(Y_tr)","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=17500), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a58694bafb42476686ab56ce8e5c6c5d"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"f65fafb60815cbf6c624d82ffcdcdba5d456f1dc"},"cell_type":"code","source":"batch_size = 32\nnb_epoch = 1000","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcc84aadd3649f68bc8243c5da4b5b28ea23e934"},"cell_type":"code","source":"%%time\n# Train model\nhistory = model.fit(X_tr, Y_tr,\n              batch_size=batch_size,\n              epochs=nb_epoch,\n              validation_split=0.1,\n              shuffle=True,\n              verbose=2)","execution_count":null,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 15750 samples, validate on 1750 samples\nEpoch 1/1000\n - 6s - loss: 0.5832 - acc: 0.6982 - val_loss: 0.4744 - val_acc: 0.7463\nEpoch 2/1000\n - 4s - loss: 0.4593 - acc: 0.7830 - val_loss: 0.3963 - val_acc: 0.7634\nEpoch 3/1000\n - 4s - loss: 0.3964 - acc: 0.8149 - val_loss: 0.3424 - val_acc: 0.8497\nEpoch 4/1000\n - 4s - loss: 0.3452 - acc: 0.8529 - val_loss: 0.3049 - val_acc: 0.8994\nEpoch 5/1000\n - 4s - loss: 0.3096 - acc: 0.8737 - val_loss: 0.2752 - val_acc: 0.9200\nEpoch 6/1000\n - 4s - loss: 0.2826 - acc: 0.8938 - val_loss: 0.2526 - val_acc: 0.9280\nEpoch 7/1000\n - 4s - loss: 0.2600 - acc: 0.9060 - val_loss: 0.2344 - val_acc: 0.9303\nEpoch 8/1000\n - 4s - loss: 0.2425 - acc: 0.9137 - val_loss: 0.2192 - val_acc: 0.9377\nEpoch 9/1000\n - 4s - loss: 0.2288 - acc: 0.9194 - val_loss: 0.2072 - val_acc: 0.9377\nEpoch 10/1000\n - 4s - loss: 0.2154 - acc: 0.9260 - val_loss: 0.1970 - val_acc: 0.9440\nEpoch 11/1000\n - 4s - loss: 0.2080 - acc: 0.9275 - val_loss: 0.1881 - val_acc: 0.9463\nEpoch 12/1000\n - 4s - loss: 0.1980 - acc: 0.9326 - val_loss: 0.1804 - val_acc: 0.9486\nEpoch 13/1000\n - 4s - loss: 0.1906 - acc: 0.9340 - val_loss: 0.1733 - val_acc: 0.9503\nEpoch 14/1000\n - 4s - loss: 0.1836 - acc: 0.9376 - val_loss: 0.1674 - val_acc: 0.9509\nEpoch 15/1000\n - 4s - loss: 0.1759 - acc: 0.9401 - val_loss: 0.1625 - val_acc: 0.9497\nEpoch 16/1000\n - 4s - loss: 0.1716 - acc: 0.9400 - val_loss: 0.1572 - val_acc: 0.9520\nEpoch 17/1000\n - 4s - loss: 0.1657 - acc: 0.9439 - val_loss: 0.1533 - val_acc: 0.9531\nEpoch 18/1000\n - 4s - loss: 0.1618 - acc: 0.9439 - val_loss: 0.1498 - val_acc: 0.9520\nEpoch 19/1000\n - 4s - loss: 0.1590 - acc: 0.9440 - val_loss: 0.1468 - val_acc: 0.9520\nEpoch 20/1000\n - 4s - loss: 0.1538 - acc: 0.9462 - val_loss: 0.1439 - val_acc: 0.9531\nEpoch 21/1000\n - 4s - loss: 0.1521 - acc: 0.9461 - val_loss: 0.1402 - val_acc: 0.9543\nEpoch 22/1000\n - 4s - loss: 0.1488 - acc: 0.9472 - val_loss: 0.1381 - val_acc: 0.9531\nEpoch 23/1000\n - 4s - loss: 0.1462 - acc: 0.9488 - val_loss: 0.1357 - val_acc: 0.9531\nEpoch 24/1000\n - 4s - loss: 0.1431 - acc: 0.9488 - val_loss: 0.1335 - val_acc: 0.9549\nEpoch 25/1000\n - 4s - loss: 0.1413 - acc: 0.9491 - val_loss: 0.1313 - val_acc: 0.9549\nEpoch 26/1000\n - 4s - loss: 0.1400 - acc: 0.9505 - val_loss: 0.1294 - val_acc: 0.9554\nEpoch 27/1000\n - 4s - loss: 0.1369 - acc: 0.9511 - val_loss: 0.1286 - val_acc: 0.9566\nEpoch 28/1000\n - 4s - loss: 0.1360 - acc: 0.9498 - val_loss: 0.1265 - val_acc: 0.9566\nEpoch 29/1000\n - 4s - loss: 0.1348 - acc: 0.9507 - val_loss: 0.1250 - val_acc: 0.9571\nEpoch 30/1000\n - 4s - loss: 0.1331 - acc: 0.9519 - val_loss: 0.1233 - val_acc: 0.9560\nEpoch 31/1000\n - 4s - loss: 0.1311 - acc: 0.9526 - val_loss: 0.1216 - val_acc: 0.9566\nEpoch 32/1000\n - 4s - loss: 0.1288 - acc: 0.9526 - val_loss: 0.1207 - val_acc: 0.9560\nEpoch 33/1000\n - 4s - loss: 0.1279 - acc: 0.9533 - val_loss: 0.1200 - val_acc: 0.9566\nEpoch 34/1000\n - 4s - loss: 0.1271 - acc: 0.9542 - val_loss: 0.1183 - val_acc: 0.9566\nEpoch 35/1000\n - 4s - loss: 0.1251 - acc: 0.9550 - val_loss: 0.1170 - val_acc: 0.9571\nEpoch 36/1000\n - 4s - loss: 0.1257 - acc: 0.9541 - val_loss: 0.1163 - val_acc: 0.9571\nEpoch 37/1000\n - 4s - loss: 0.1240 - acc: 0.9547 - val_loss: 0.1149 - val_acc: 0.9577\nEpoch 38/1000\n - 4s - loss: 0.1213 - acc: 0.9573 - val_loss: 0.1146 - val_acc: 0.9577\nEpoch 39/1000\n - 4s - loss: 0.1213 - acc: 0.9552 - val_loss: 0.1130 - val_acc: 0.9577\nEpoch 40/1000\n - 4s - loss: 0.1202 - acc: 0.9557 - val_loss: 0.1122 - val_acc: 0.9577\nEpoch 41/1000\n - 4s - loss: 0.1180 - acc: 0.9578 - val_loss: 0.1114 - val_acc: 0.9577\nEpoch 42/1000\n - 4s - loss: 0.1192 - acc: 0.9570 - val_loss: 0.1105 - val_acc: 0.9594\nEpoch 43/1000\n - 4s - loss: 0.1184 - acc: 0.9559 - val_loss: 0.1102 - val_acc: 0.9577\nEpoch 44/1000\n - 4s - loss: 0.1175 - acc: 0.9589 - val_loss: 0.1093 - val_acc: 0.9589\nEpoch 45/1000\n - 4s - loss: 0.1145 - acc: 0.9590 - val_loss: 0.1089 - val_acc: 0.9583\nEpoch 46/1000\n - 4s - loss: 0.1156 - acc: 0.9577 - val_loss: 0.1081 - val_acc: 0.9606\nEpoch 47/1000\n - 4s - loss: 0.1150 - acc: 0.9585 - val_loss: 0.1077 - val_acc: 0.9611\nEpoch 48/1000\n - 4s - loss: 0.1136 - acc: 0.9571 - val_loss: 0.1072 - val_acc: 0.9611\nEpoch 49/1000\n - 4s - loss: 0.1129 - acc: 0.9578 - val_loss: 0.1064 - val_acc: 0.9611\nEpoch 50/1000\n - 4s - loss: 0.1128 - acc: 0.9591 - val_loss: 0.1054 - val_acc: 0.9611\nEpoch 51/1000\n - 4s - loss: 0.1103 - acc: 0.9605 - val_loss: 0.1049 - val_acc: 0.9617\nEpoch 52/1000\n - 4s - loss: 0.1107 - acc: 0.9590 - val_loss: 0.1046 - val_acc: 0.9629\nEpoch 53/1000\n - 4s - loss: 0.1090 - acc: 0.9591 - val_loss: 0.1035 - val_acc: 0.9611\nEpoch 54/1000\n - 4s - loss: 0.1102 - acc: 0.9599 - val_loss: 0.1038 - val_acc: 0.9623\nEpoch 55/1000\n - 4s - loss: 0.1089 - acc: 0.9612 - val_loss: 0.1031 - val_acc: 0.9629\nEpoch 56/1000\n - 4s - loss: 0.1083 - acc: 0.9602 - val_loss: 0.1022 - val_acc: 0.9634\nEpoch 57/1000\n - 4s - loss: 0.1076 - acc: 0.9621 - val_loss: 0.1020 - val_acc: 0.9629\nEpoch 58/1000\n - 4s - loss: 0.1065 - acc: 0.9620 - val_loss: 0.1010 - val_acc: 0.9634\nEpoch 59/1000\n - 4s - loss: 0.1059 - acc: 0.9614 - val_loss: 0.1006 - val_acc: 0.9629\nEpoch 60/1000\n - 4s - loss: 0.1055 - acc: 0.9614 - val_loss: 0.1003 - val_acc: 0.9634\nEpoch 61/1000\n - 4s - loss: 0.1048 - acc: 0.9619 - val_loss: 0.0998 - val_acc: 0.9634\nEpoch 62/1000\n - 4s - loss: 0.1048 - acc: 0.9620 - val_loss: 0.1002 - val_acc: 0.9634\nEpoch 63/1000\n - 4s - loss: 0.1059 - acc: 0.9601 - val_loss: 0.0994 - val_acc: 0.9640\nEpoch 64/1000\n - 4s - loss: 0.1039 - acc: 0.9622 - val_loss: 0.0985 - val_acc: 0.9634\nEpoch 65/1000\n - 4s - loss: 0.1042 - acc: 0.9609 - val_loss: 0.0980 - val_acc: 0.9634\nEpoch 66/1000\n - 4s - loss: 0.1027 - acc: 0.9630 - val_loss: 0.0979 - val_acc: 0.9640\nEpoch 67/1000\n - 4s - loss: 0.1019 - acc: 0.9618 - val_loss: 0.0981 - val_acc: 0.9640\nEpoch 68/1000\n - 4s - loss: 0.1018 - acc: 0.9632 - val_loss: 0.0970 - val_acc: 0.9634\nEpoch 69/1000\n - 4s - loss: 0.1025 - acc: 0.9608 - val_loss: 0.0963 - val_acc: 0.9640\nEpoch 70/1000\n - 4s - loss: 0.1003 - acc: 0.9628 - val_loss: 0.0964 - val_acc: 0.9634\nEpoch 71/1000\n - 4s - loss: 0.1008 - acc: 0.9630 - val_loss: 0.0963 - val_acc: 0.9646\nEpoch 72/1000\n - 4s - loss: 0.0989 - acc: 0.9645 - val_loss: 0.0958 - val_acc: 0.9634\nEpoch 73/1000\n - 4s - loss: 0.1004 - acc: 0.9630 - val_loss: 0.0951 - val_acc: 0.9640\nEpoch 74/1000\n - 4s - loss: 0.1012 - acc: 0.9623 - val_loss: 0.0949 - val_acc: 0.9634\nEpoch 75/1000\n - 4s - loss: 0.0978 - acc: 0.9639 - val_loss: 0.0945 - val_acc: 0.9640\nEpoch 76/1000\n - 4s - loss: 0.0983 - acc: 0.9643 - val_loss: 0.0942 - val_acc: 0.9640\nEpoch 77/1000\n - 4s - loss: 0.0979 - acc: 0.9635 - val_loss: 0.0937 - val_acc: 0.9646\nEpoch 78/1000\n - 4s - loss: 0.0984 - acc: 0.9636 - val_loss: 0.0934 - val_acc: 0.9646\nEpoch 79/1000\n - 4s - loss: 0.0979 - acc: 0.9633 - val_loss: 0.0934 - val_acc: 0.9640\nEpoch 80/1000\n - 4s - loss: 0.0969 - acc: 0.9649 - val_loss: 0.0928 - val_acc: 0.9646\nEpoch 81/1000\n - 4s - loss: 0.0956 - acc: 0.9646 - val_loss: 0.0932 - val_acc: 0.9640\nEpoch 82/1000\n - 4s - loss: 0.0959 - acc: 0.9647 - val_loss: 0.0919 - val_acc: 0.9646\nEpoch 83/1000\n - 4s - loss: 0.0950 - acc: 0.9644 - val_loss: 0.0916 - val_acc: 0.9651\nEpoch 84/1000\n - 4s - loss: 0.0951 - acc: 0.9642 - val_loss: 0.0919 - val_acc: 0.9651\nEpoch 85/1000\n - 4s - loss: 0.0943 - acc: 0.9650 - val_loss: 0.0913 - val_acc: 0.9646\nEpoch 86/1000\n - 4s - loss: 0.0944 - acc: 0.9657 - val_loss: 0.0918 - val_acc: 0.9646\nEpoch 87/1000\n - 4s - loss: 0.0944 - acc: 0.9652 - val_loss: 0.0905 - val_acc: 0.9646\nEpoch 88/1000\n - 4s - loss: 0.0932 - acc: 0.9656 - val_loss: 0.0907 - val_acc: 0.9651\nEpoch 89/1000\n - 4s - loss: 0.0934 - acc: 0.9652 - val_loss: 0.0903 - val_acc: 0.9646\nEpoch 90/1000\n - 4s - loss: 0.0935 - acc: 0.9662 - val_loss: 0.0897 - val_acc: 0.9663\nEpoch 91/1000\n - 4s - loss: 0.0931 - acc: 0.9653 - val_loss: 0.0896 - val_acc: 0.9646\nEpoch 92/1000\n - 4s - loss: 0.0926 - acc: 0.9663 - val_loss: 0.0892 - val_acc: 0.9663\n","name":"stdout"},{"output_type":"stream","text":"Epoch 93/1000\n - 4s - loss: 0.0922 - acc: 0.9660 - val_loss: 0.0890 - val_acc: 0.9646\nEpoch 94/1000\n - 4s - loss: 0.0928 - acc: 0.9650 - val_loss: 0.0890 - val_acc: 0.9646\nEpoch 95/1000\n - 4s - loss: 0.0920 - acc: 0.9663 - val_loss: 0.0886 - val_acc: 0.9663\nEpoch 96/1000\n - 4s - loss: 0.0909 - acc: 0.9668 - val_loss: 0.0884 - val_acc: 0.9657\nEpoch 97/1000\n - 4s - loss: 0.0912 - acc: 0.9667 - val_loss: 0.0883 - val_acc: 0.9646\nEpoch 98/1000\n - 4s - loss: 0.0912 - acc: 0.9670 - val_loss: 0.0881 - val_acc: 0.9657\nEpoch 99/1000\n - 4s - loss: 0.0900 - acc: 0.9669 - val_loss: 0.0876 - val_acc: 0.9663\nEpoch 100/1000\n - 4s - loss: 0.0897 - acc: 0.9677 - val_loss: 0.0876 - val_acc: 0.9646\nEpoch 101/1000\n - 4s - loss: 0.0892 - acc: 0.9682 - val_loss: 0.0872 - val_acc: 0.9663\nEpoch 102/1000\n - 4s - loss: 0.0893 - acc: 0.9670 - val_loss: 0.0870 - val_acc: 0.9663\nEpoch 103/1000\n - 4s - loss: 0.0895 - acc: 0.9667 - val_loss: 0.0868 - val_acc: 0.9663\nEpoch 104/1000\n - 4s - loss: 0.0891 - acc: 0.9678 - val_loss: 0.0868 - val_acc: 0.9663\nEpoch 105/1000\n - 4s - loss: 0.0898 - acc: 0.9673 - val_loss: 0.0863 - val_acc: 0.9669\nEpoch 106/1000\n - 4s - loss: 0.0875 - acc: 0.9672 - val_loss: 0.0860 - val_acc: 0.9663\nEpoch 107/1000\n - 4s - loss: 0.0887 - acc: 0.9670 - val_loss: 0.0859 - val_acc: 0.9663\nEpoch 108/1000\n - 4s - loss: 0.0884 - acc: 0.9676 - val_loss: 0.0857 - val_acc: 0.9663\nEpoch 109/1000\n - 4s - loss: 0.0873 - acc: 0.9681 - val_loss: 0.0856 - val_acc: 0.9663\nEpoch 110/1000\n - 4s - loss: 0.0876 - acc: 0.9681 - val_loss: 0.0852 - val_acc: 0.9669\nEpoch 111/1000\n - 4s - loss: 0.0870 - acc: 0.9666 - val_loss: 0.0853 - val_acc: 0.9663\nEpoch 112/1000\n - 4s - loss: 0.0873 - acc: 0.9674 - val_loss: 0.0851 - val_acc: 0.9663\nEpoch 113/1000\n - 4s - loss: 0.0868 - acc: 0.9683 - val_loss: 0.0846 - val_acc: 0.9669\nEpoch 114/1000\n - 4s - loss: 0.0857 - acc: 0.9689 - val_loss: 0.0846 - val_acc: 0.9663\nEpoch 115/1000\n - 4s - loss: 0.0861 - acc: 0.9693 - val_loss: 0.0844 - val_acc: 0.9674\nEpoch 116/1000\n - 4s - loss: 0.0865 - acc: 0.9690 - val_loss: 0.0841 - val_acc: 0.9669\nEpoch 117/1000\n - 4s - loss: 0.0851 - acc: 0.9691 - val_loss: 0.0840 - val_acc: 0.9674\nEpoch 118/1000\n - 4s - loss: 0.0862 - acc: 0.9684 - val_loss: 0.0841 - val_acc: 0.9669\nEpoch 119/1000\n - 4s - loss: 0.0850 - acc: 0.9689 - val_loss: 0.0836 - val_acc: 0.9680\nEpoch 120/1000\n - 4s - loss: 0.0856 - acc: 0.9684 - val_loss: 0.0839 - val_acc: 0.9674\nEpoch 121/1000\n - 4s - loss: 0.0846 - acc: 0.9696 - val_loss: 0.0835 - val_acc: 0.9669\nEpoch 122/1000\n - 4s - loss: 0.0852 - acc: 0.9683 - val_loss: 0.0831 - val_acc: 0.9680\nEpoch 123/1000\n - 4s - loss: 0.0841 - acc: 0.9694 - val_loss: 0.0831 - val_acc: 0.9680\nEpoch 124/1000\n - 4s - loss: 0.0847 - acc: 0.9691 - val_loss: 0.0829 - val_acc: 0.9680\nEpoch 125/1000\n - 4s - loss: 0.0847 - acc: 0.9679 - val_loss: 0.0829 - val_acc: 0.9686\nEpoch 126/1000\n - 4s - loss: 0.0839 - acc: 0.9686 - val_loss: 0.0827 - val_acc: 0.9686\nEpoch 127/1000\n - 4s - loss: 0.0833 - acc: 0.9697 - val_loss: 0.0821 - val_acc: 0.9680\nEpoch 128/1000\n - 4s - loss: 0.0832 - acc: 0.9701 - val_loss: 0.0820 - val_acc: 0.9680\nEpoch 129/1000\n - 4s - loss: 0.0824 - acc: 0.9690 - val_loss: 0.0821 - val_acc: 0.9686\nEpoch 130/1000\n - 4s - loss: 0.0825 - acc: 0.9702 - val_loss: 0.0819 - val_acc: 0.9686\nEpoch 131/1000\n - 4s - loss: 0.0826 - acc: 0.9690 - val_loss: 0.0818 - val_acc: 0.9686\nEpoch 132/1000\n - 4s - loss: 0.0824 - acc: 0.9690 - val_loss: 0.0819 - val_acc: 0.9686\nEpoch 133/1000\n - 4s - loss: 0.0816 - acc: 0.9702 - val_loss: 0.0815 - val_acc: 0.9686\nEpoch 134/1000\n - 4s - loss: 0.0826 - acc: 0.9691 - val_loss: 0.0812 - val_acc: 0.9686\nEpoch 135/1000\n - 4s - loss: 0.0812 - acc: 0.9697 - val_loss: 0.0816 - val_acc: 0.9686\nEpoch 136/1000\n - 4s - loss: 0.0809 - acc: 0.9698 - val_loss: 0.0814 - val_acc: 0.9686\nEpoch 137/1000\n - 4s - loss: 0.0801 - acc: 0.9700 - val_loss: 0.0811 - val_acc: 0.9686\nEpoch 138/1000\n - 4s - loss: 0.0807 - acc: 0.9707 - val_loss: 0.0810 - val_acc: 0.9686\nEpoch 139/1000\n - 4s - loss: 0.0815 - acc: 0.9698 - val_loss: 0.0812 - val_acc: 0.9680\nEpoch 140/1000\n - 4s - loss: 0.0798 - acc: 0.9700 - val_loss: 0.0806 - val_acc: 0.9686\nEpoch 141/1000\n - 4s - loss: 0.0804 - acc: 0.9697 - val_loss: 0.0802 - val_acc: 0.9686\nEpoch 142/1000\n - 4s - loss: 0.0802 - acc: 0.9701 - val_loss: 0.0801 - val_acc: 0.9686\nEpoch 143/1000\n - 4s - loss: 0.0794 - acc: 0.9708 - val_loss: 0.0806 - val_acc: 0.9686\nEpoch 144/1000\n - 4s - loss: 0.0793 - acc: 0.9702 - val_loss: 0.0800 - val_acc: 0.9686\nEpoch 145/1000\n - 4s - loss: 0.0804 - acc: 0.9697 - val_loss: 0.0798 - val_acc: 0.9686\nEpoch 146/1000\n - 4s - loss: 0.0794 - acc: 0.9710 - val_loss: 0.0799 - val_acc: 0.9686\nEpoch 147/1000\n - 4s - loss: 0.0789 - acc: 0.9712 - val_loss: 0.0796 - val_acc: 0.9686\nEpoch 148/1000\n - 4s - loss: 0.0785 - acc: 0.9704 - val_loss: 0.0793 - val_acc: 0.9686\nEpoch 149/1000\n - 4s - loss: 0.0789 - acc: 0.9704 - val_loss: 0.0795 - val_acc: 0.9691\nEpoch 150/1000\n - 4s - loss: 0.0785 - acc: 0.9714 - val_loss: 0.0790 - val_acc: 0.9686\nEpoch 151/1000\n - 4s - loss: 0.0786 - acc: 0.9722 - val_loss: 0.0789 - val_acc: 0.9686\nEpoch 152/1000\n - 4s - loss: 0.0778 - acc: 0.9709 - val_loss: 0.0788 - val_acc: 0.9686\nEpoch 153/1000\n - 4s - loss: 0.0778 - acc: 0.9721 - val_loss: 0.0792 - val_acc: 0.9697\nEpoch 154/1000\n - 4s - loss: 0.0778 - acc: 0.9707 - val_loss: 0.0786 - val_acc: 0.9691\nEpoch 155/1000\n - 4s - loss: 0.0789 - acc: 0.9710 - val_loss: 0.0784 - val_acc: 0.9686\nEpoch 156/1000\n - 4s - loss: 0.0774 - acc: 0.9708 - val_loss: 0.0784 - val_acc: 0.9691\nEpoch 157/1000\n - 4s - loss: 0.0779 - acc: 0.9719 - val_loss: 0.0786 - val_acc: 0.9691\nEpoch 158/1000\n - 4s - loss: 0.0777 - acc: 0.9709 - val_loss: 0.0781 - val_acc: 0.9691\nEpoch 159/1000\n - 4s - loss: 0.0764 - acc: 0.9715 - val_loss: 0.0781 - val_acc: 0.9686\nEpoch 160/1000\n - 4s - loss: 0.0775 - acc: 0.9718 - val_loss: 0.0779 - val_acc: 0.9691\nEpoch 161/1000\n - 4s - loss: 0.0771 - acc: 0.9716 - val_loss: 0.0777 - val_acc: 0.9691\nEpoch 162/1000\n - 4s - loss: 0.0773 - acc: 0.9717 - val_loss: 0.0775 - val_acc: 0.9691\nEpoch 163/1000\n - 4s - loss: 0.0763 - acc: 0.9712 - val_loss: 0.0779 - val_acc: 0.9691\nEpoch 164/1000\n - 4s - loss: 0.0775 - acc: 0.9720 - val_loss: 0.0773 - val_acc: 0.9697\nEpoch 165/1000\n - 4s - loss: 0.0757 - acc: 0.9726 - val_loss: 0.0775 - val_acc: 0.9691\nEpoch 166/1000\n - 4s - loss: 0.0759 - acc: 0.9735 - val_loss: 0.0773 - val_acc: 0.9691\nEpoch 167/1000\n - 4s - loss: 0.0750 - acc: 0.9731 - val_loss: 0.0770 - val_acc: 0.9703\nEpoch 168/1000\n - 4s - loss: 0.0760 - acc: 0.9728 - val_loss: 0.0769 - val_acc: 0.9697\nEpoch 169/1000\n - 4s - loss: 0.0757 - acc: 0.9723 - val_loss: 0.0772 - val_acc: 0.9691\nEpoch 170/1000\n - 4s - loss: 0.0767 - acc: 0.9714 - val_loss: 0.0769 - val_acc: 0.9691\nEpoch 171/1000\n - 4s - loss: 0.0748 - acc: 0.9720 - val_loss: 0.0766 - val_acc: 0.9697\nEpoch 172/1000\n - 4s - loss: 0.0752 - acc: 0.9730 - val_loss: 0.0766 - val_acc: 0.9697\nEpoch 173/1000\n - 4s - loss: 0.0749 - acc: 0.9731 - val_loss: 0.0764 - val_acc: 0.9697\nEpoch 174/1000\n - 4s - loss: 0.0747 - acc: 0.9732 - val_loss: 0.0767 - val_acc: 0.9691\nEpoch 175/1000\n - 4s - loss: 0.0732 - acc: 0.9726 - val_loss: 0.0765 - val_acc: 0.9691\nEpoch 176/1000\n - 4s - loss: 0.0749 - acc: 0.9730 - val_loss: 0.0763 - val_acc: 0.9691\nEpoch 177/1000\n - 4s - loss: 0.0746 - acc: 0.9726 - val_loss: 0.0763 - val_acc: 0.9691\nEpoch 178/1000\n - 4s - loss: 0.0737 - acc: 0.9727 - val_loss: 0.0760 - val_acc: 0.9691\nEpoch 179/1000\n - 4s - loss: 0.0737 - acc: 0.9731 - val_loss: 0.0767 - val_acc: 0.9714\nEpoch 180/1000\n - 4s - loss: 0.0735 - acc: 0.9726 - val_loss: 0.0763 - val_acc: 0.9697\nEpoch 181/1000\n - 4s - loss: 0.0746 - acc: 0.9722 - val_loss: 0.0759 - val_acc: 0.9691\nEpoch 182/1000\n - 4s - loss: 0.0749 - acc: 0.9726 - val_loss: 0.0756 - val_acc: 0.9703\nEpoch 183/1000\n - 4s - loss: 0.0724 - acc: 0.9731 - val_loss: 0.0757 - val_acc: 0.9691\nEpoch 184/1000\n - 4s - loss: 0.0729 - acc: 0.9726 - val_loss: 0.0754 - val_acc: 0.9703\nEpoch 185/1000\n - 4s - loss: 0.0721 - acc: 0.9731 - val_loss: 0.0753 - val_acc: 0.9703\nEpoch 186/1000\n - 4s - loss: 0.0730 - acc: 0.9741 - val_loss: 0.0754 - val_acc: 0.9697\nEpoch 187/1000\n - 4s - loss: 0.0730 - acc: 0.9729 - val_loss: 0.0752 - val_acc: 0.9703\n","name":"stdout"},{"output_type":"stream","text":"Epoch 188/1000\n - 4s - loss: 0.0721 - acc: 0.9728 - val_loss: 0.0754 - val_acc: 0.9697\nEpoch 189/1000\n - 4s - loss: 0.0717 - acc: 0.9735 - val_loss: 0.0753 - val_acc: 0.9697\nEpoch 190/1000\n - 4s - loss: 0.0727 - acc: 0.9752 - val_loss: 0.0750 - val_acc: 0.9709\nEpoch 191/1000\n - 4s - loss: 0.0722 - acc: 0.9738 - val_loss: 0.0750 - val_acc: 0.9709\nEpoch 192/1000\n - 4s - loss: 0.0721 - acc: 0.9735 - val_loss: 0.0748 - val_acc: 0.9709\nEpoch 193/1000\n - 4s - loss: 0.0720 - acc: 0.9731 - val_loss: 0.0748 - val_acc: 0.9709\nEpoch 194/1000\n - 4s - loss: 0.0722 - acc: 0.9732 - val_loss: 0.0748 - val_acc: 0.9703\nEpoch 195/1000\n - 4s - loss: 0.0716 - acc: 0.9731 - val_loss: 0.0748 - val_acc: 0.9703\nEpoch 196/1000\n - 4s - loss: 0.0715 - acc: 0.9740 - val_loss: 0.0746 - val_acc: 0.9697\nEpoch 197/1000\n - 4s - loss: 0.0717 - acc: 0.9735 - val_loss: 0.0744 - val_acc: 0.9703\nEpoch 198/1000\n - 4s - loss: 0.0716 - acc: 0.9723 - val_loss: 0.0743 - val_acc: 0.9709\nEpoch 199/1000\n - 4s - loss: 0.0715 - acc: 0.9737 - val_loss: 0.0742 - val_acc: 0.9709\nEpoch 200/1000\n - 4s - loss: 0.0718 - acc: 0.9735 - val_loss: 0.0743 - val_acc: 0.9703\nEpoch 201/1000\n - 4s - loss: 0.0702 - acc: 0.9749 - val_loss: 0.0739 - val_acc: 0.9703\nEpoch 202/1000\n - 4s - loss: 0.0709 - acc: 0.9743 - val_loss: 0.0738 - val_acc: 0.9703\nEpoch 203/1000\n - 4s - loss: 0.0703 - acc: 0.9744 - val_loss: 0.0739 - val_acc: 0.9703\nEpoch 204/1000\n - 4s - loss: 0.0705 - acc: 0.9736 - val_loss: 0.0737 - val_acc: 0.9709\nEpoch 205/1000\n - 4s - loss: 0.0697 - acc: 0.9743 - val_loss: 0.0740 - val_acc: 0.9709\nEpoch 206/1000\n - 4s - loss: 0.0698 - acc: 0.9737 - val_loss: 0.0735 - val_acc: 0.9709\nEpoch 207/1000\n - 4s - loss: 0.0704 - acc: 0.9735 - val_loss: 0.0735 - val_acc: 0.9709\nEpoch 208/1000\n - 4s - loss: 0.0709 - acc: 0.9743 - val_loss: 0.0733 - val_acc: 0.9709\nEpoch 209/1000\n - 4s - loss: 0.0699 - acc: 0.9744 - val_loss: 0.0734 - val_acc: 0.9709\nEpoch 210/1000\n - 4s - loss: 0.0699 - acc: 0.9740 - val_loss: 0.0732 - val_acc: 0.9709\nEpoch 211/1000\n - 4s - loss: 0.0688 - acc: 0.9750 - val_loss: 0.0731 - val_acc: 0.9714\nEpoch 212/1000\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"5d3b65c4f037811a2dd5c10dfe7aa73ecbf18f66"},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"886bbad30809f3f625131c5dbe8ad81fad59775f"},"cell_type":"code","source":"%%time\nX_tst = []\nTest_imgs = []\nfor img_id in tqdm_notebook(os.listdir(test_dir)):\n    X_tst.append(cv2.imread(test_dir + img_id))     \n    Test_imgs.append(img_id)\nX_tst = np.asarray(X_tst)\nX_tst = X_tst.astype('float32')\nX_tst /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87b606b5682862e89e6a636bb6741c5322aa7f94"},"cell_type":"code","source":"# Prediction\ntest_predictions = model.predict(X_tst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef44e90a01a71ac344a9e9fcd132a579f6ac4e17"},"cell_type":"code","source":"sub_df = pd.DataFrame(test_predictions, columns=['has_cactus'])\nsub_df['has_cactus'] = sub_df['has_cactus'].apply(lambda x: 1 if x > 0.75 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf15ba71202c72f5de2b267facc3fc61ee4e2662"},"cell_type":"code","source":"sub_df['id'] = ''\ncols = sub_df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsub_df=sub_df[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47f462b44ed8f40192bb03ba9663b1b2cac1b760"},"cell_type":"code","source":"for i, img in enumerate(Test_imgs):\n    sub_df.set_value(i,'id',img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d39f86acffc3043e9bc0e99f95b820b5a400e8f"},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5544610769599ff02920e239e78590ddd93e0e6f"},"cell_type":"code","source":"sub_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}